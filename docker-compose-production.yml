# ═══════════════════════════════════════════════════════════════════
# IoT-DevSim - PRODUCTION DOCKER COMPOSE
# ═══════════════════════════════════════════════════════════════════
# This file is for PRODUCTION DEPLOYMENT ONLY.
# It uses production Docker targets and does not mount source code.
#
# Usage:
#   docker-compose -f docker-compose-production.yml up -d
#
# Prerequisites:
#   - .env.production file with secure secrets
#   - SSL certificates configured (or use reverse proxy)
#   - Database migrations applied
# ═══════════════════════════════════════════════════════════════════

version: '3.8'

services:
  # ═════════════════════════════════════════════════════════════════
  # PostgreSQL Database
  # ═════════════════════════════════════════════════════════════════
  postgres:
    image: postgres:17-alpine
    container_name: iot-devsim-postgres-prod
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d:ro
    # NO external port exposure - internal network only
    networks:
      - iot-network-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ═════════════════════════════════════════════════════════════════
  # Frontend - Production (Nginx serving React build)
  # ═════════════════════════════════════════════════════════════════
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        # Build-time variables for Vite
        VITE_API_URL: ${VITE_API_URL}
        VITE_WS_URL: ${VITE_WS_URL}
        VITE_ENVIRONMENT: production
    container_name: iot-devsim-frontend-prod
    restart: always
    ports:
      - "${FRONTEND_PORT:-80}:80"
    networks:
      - iot-network-internal
      - iot-network-external
    depends_on:
      api-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ═════════════════════════════════════════════════════════════════
  # Redis - With Authentication
  # ═════════════════════════════════════════════════════════════════
  redis:
    image: redis:8-alpine
    container_name: iot-devsim-redis-prod
    restart: always
    # NO external port exposure - internal network only
    networks:
      - iot-network-internal
    volumes:
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # ═════════════════════════════════════════════════════════════════
  # API Service - Production
  # ═════════════════════════════════════════════════════════════════
  api-service:
    build:
      context: ./api-service
      dockerfile: Dockerfile
      target: production
    container_name: iot-devsim-api-prod
    restart: always
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - JWT_ALGORITHM=${JWT_ALGORITHM}
      - JWT_ACCESS_TOKEN_EXPIRE_MINUTES=${JWT_ACCESS_TOKEN_EXPIRE_MINUTES}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - ALLOWED_HOSTS=${ALLOWED_HOSTS}
      - BCRYPT_ROUNDS=${BCRYPT_ROUNDS}
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE}
      - MAX_UPLOAD_SIZE=${MAX_UPLOAD_SIZE}
      - LOG_LEVEL=${LOG_LEVEL}
      - LOG_FORMAT=${LOG_FORMAT}
      - PYTHONPATH=/app
      - STORAGE_BACKEND=${STORAGE_BACKEND}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_BUCKET=${S3_BUCKET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_REGION=${S3_REGION}
    # NO source code mounts - only logs and uploads
    volumes:
      - api_logs:/app/logs
      - uploads_data:/app/uploads
    ports:
      - "${API_PORT:-8000}:8000"
    networks:
      - iot-network-internal
      - iot-network-external
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # Production command uses Gunicorn (defined in Dockerfile)
    # No --reload flag in production
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ═════════════════════════════════════════════════════════════════
  # Transmission Service - Production
  # ═════════════════════════════════════════════════════════════════
  transmission-service:
    build:
      context: ./transmission-service
      dockerfile: Dockerfile
      target: production
    container_name: iot-devsim-transmission-prod
    restart: always
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/1
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - MQTT_BROKER_HOST=${MQTT_BROKER_HOST}
      - MQTT_BROKER_PORT=${MQTT_BROKER_PORT}
      - MQTT_USE_TLS=${MQTT_USE_TLS}
      - MQTT_USERNAME=${MQTT_USERNAME}
      - MQTT_PASSWORD=${MQTT_PASSWORD}
      - TRANSMISSION_BATCH_SIZE=${TRANSMISSION_BATCH_SIZE}
      - TRANSMISSION_INTERVAL_MS=${TRANSMISSION_INTERVAL_MS}
      - DATASETS_BASE_PATH=/app/uploads
      - STORAGE_BACKEND=${STORAGE_BACKEND:-local}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_BUCKET=${S3_BUCKET:-iot-devsim-datasets}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_REGION=${S3_REGION:-us-east-1}
      - LOG_LEVEL=${LOG_LEVEL}
      - LOG_FORMAT=${LOG_FORMAT}
      - PYTHONPATH=/app
    # NO source code mounts - only logs and shared uploads
    volumes:
      - transmission_logs:/app/logs
      - uploads_data:/app/uploads
    ports:
      - "${TRANSMISSION_PORT:-8001}:8001"
    networks:
      - iot-network-internal
      - iot-network-external
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ═════════════════════════════════════════════════════════════════
  # Celery Worker - Production (Optional)
  # ═════════════════════════════════════════════════════════════════
  celery-worker:
    build:
      context: ./api-service
      dockerfile: Dockerfile
      target: production
    container_name: iot-devsim-celery-worker-prod
    restart: always
    environment:
      - ENVIRONMENT=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - LOG_LEVEL=${LOG_LEVEL}
      - LOG_FORMAT=${LOG_FORMAT}
      - PYTHONPATH=/app
      - STORAGE_BACKEND=${STORAGE_BACKEND}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - S3_BUCKET=${S3_BUCKET}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_REGION=${S3_REGION}
    # NO source code mounts
    volumes:
      - api_logs:/app/logs
      - uploads_data:/app/uploads
    networks:
      - iot-network-internal
    depends_on:
      - redis
      - postgres
    command: celery -A app.core.celery_app:celery_app worker --loglevel=${LOG_LEVEL:-warning} --concurrency=2
    profiles:
      - worker
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ═════════════════════════════════════════════════════════════════
  # MinIO - Object Storage (Optional)
  # ═════════════════════════════════════════════════════════════════
  minio:
    image: minio/minio:latest
    container_name: iot-devsim-minio-prod
    restart: always
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    # NO external port exposure - internal only or through reverse proxy
    networks:
      - iot-network-internal
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: server /data --console-address ":9001"
    profiles:
      - storage
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # ═════════════════════════════════════════════════════════════════
  # PostgreSQL Backup Service (Optional)
  # ═════════════════════════════════════════════════════════════════
  postgres-backup:
    image: postgres:17-alpine
    container_name: iot-devsim-postgres-backup
    restart: unless-stopped
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      BACKUP_RETENTION_DAYS: ${BACKUP_RETENTION_DAYS:-7}
    volumes:
      - /backup/postgres:/backups
    networks:
      - iot-network-internal
    depends_on:
      - postgres
    command: >
      sh -c '
      echo "Starting backup service - retention: $${BACKUP_RETENTION_DAYS} days" &&
      while true; do
        echo "[$$(date)] Creating backup..." &&
        pg_dump -h postgres -U $${POSTGRES_USER} -d $${POSTGRES_DB} > /backups/backup_$$(date +%Y%m%d_%H%M%S).sql &&
        echo "[$$(date)] Backup completed. Cleaning old backups..." &&
        find /backups -name "backup_*.sql" -mtime +$${BACKUP_RETENTION_DAYS} -delete &&
        echo "[$$(date)] Next backup in 24 hours" &&
        sleep 86400
      done'
    profiles:
      - backup
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ═══════════════════════════════════════════════════════════════════
# VOLUMES
# ═══════════════════════════════════════════════════════════════════
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  api_logs:
    driver: local
  transmission_logs:
    driver: local
  uploads_data:
    driver: local
  minio_data:
    driver: local

# ═══════════════════════════════════════════════════════════════════
# NETWORKS
# ═══════════════════════════════════════════════════════════════════
# Separate internal and external networks for security
networks:
  # Internal network - only for service-to-service communication
  iot-network-internal:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.20.0.0/16
  # External network - for services that need external access
  iot-network-external:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16
